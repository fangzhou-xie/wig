
From the Wasserstein Dictionary Learning problem described as \cref{eqn:wasserstein-dictionary-problem-unconstrained}
in \cref{subsec:wasserstein-dictionary-learning},
we can describe the solution algorithm and its gradient calculation.
Therefore, we could write the parameter updating algorithm as well.
The routine has been described in \cref{subsec:wasserstein-dictionary-learning},
but now I give all the details in this subsection.

The loss function $\mathcal{L}$ here under consideration in this paper would be quadratic loss\footnote{
  Though other losses can also be used,
  for example see \citet[Table 1]{schmitz2018} for different loss functions and their gradients.
},
i.e. $\mathcal{L}(\mathbf{p}, \mathbf{q}) = \lVert \mathbf{p} - \mathbf{q}\rVert_2^2.$
